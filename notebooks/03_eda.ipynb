{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Exploratory Data Analysis\n",
    "Quick exploration of job postings sourced from the scraper or a baked-in sample dataset. This notebook now includes deeper analysis of job titles, companies, locations, and text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pip-install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-path",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Resolve repo root whether running from notebook dir or project root\n",
    "repo_root = Path(__file__).resolve().parents[1] if \"__file__\" in globals() else Path.cwd().resolve()\n",
    "if not (repo_root / \"src\").exists():\n",
    "    for parent in repo_root.parents:\n",
    "        if (parent / \"src\").exists():\n",
    "            repo_root = parent\n",
    "            break\n",
    "\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.append(str(repo_root))\n",
    "\n",
    "print(f\"Repo root: {repo_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from src.storage.json_repository import JSONJobStore\n",
    "from src.preprocessing.text_cleaner import TextCleaner\n",
    "from src.preprocessing.skill_extractor import SkillExtractor\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b350a",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct absolute path to the data file using repo_root\n",
    "data_path = repo_root / \"data/processed/adzuna_data_jobs.json\"\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "store = JSONJobStore(json_path=data_path)\n",
    "records = store.recent(limit=1000)  # Increased limit to get more data\n",
    "\n",
    "if records:\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"job_title\": [r.job_title for r in records],\n",
    "            \"job_description\": [r.job_description for r in records],\n",
    "            \"company\": [r.company for r in records],\n",
    "            \"location\": [r.location for r in records],\n",
    "            \"posted_date\": [r.posted_date for r in records],\n",
    "            \"source\": [r.source for r in records],\n",
    "            \"fetched_at\": [r.fetched_at for r in records],\n",
    "        }\n",
    "    )\n",
    "    print(f\"Loaded {len(df)} job records.\")\n",
    "else:\n",
    "    print(\"No records found in JSONJobStore.\")\n",
    "    df = pd.DataFrame() # Create empty DF to prevent errors\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989579a2",
   "metadata": {},
   "source": [
    "## 2. Categorical Analysis\n",
    "Analyzing the distribution of Job Titles, Companies, and Locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-job-titles",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df['job_title'].value_counts().head(20).plot(kind='barh', color='skyblue')\n",
    "    plt.title('Top 20 Job Titles')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Job Title')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-companies",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df['company'].value_counts().head(20).plot(kind='barh', color='salmon')\n",
    "    plt.title('Top 20 Hiring Companies')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Company')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-locations",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df['location'].value_counts().head(20).plot(kind='barh', color='lightgreen')\n",
    "    plt.title('Top 20 Job Locations')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Location')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421a569",
   "metadata": {},
   "source": [
    "## 3. Quantitative Analysis\n",
    "Analyzing the length of job descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-desc-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    df['desc_length'] = df['job_description'].fillna('').apply(len)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['desc_length'], bins=30, kde=True, color='purple')\n",
    "    plt.title('Distribution of Job Description Lengths')\n",
    "    plt.xlabel('Character Count')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21343ca4",
   "metadata": {},
   "source": [
    "## 4. Text Analysis & Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "text-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    cleaner = TextCleaner(stopwords={\"and\", \"with\", \"the\", \"to\", \"in\", \"for\", \"of\", \"a\", \"an\", \"on\", \"is\", \"are\"})\n",
    "    df[\"clean_description\"] = df[\"job_description\"].fillna(\"\").apply(cleaner.clean)\n",
    "    \n",
    "    # Extract all text for word cloud\n",
    "    all_text = \" \".join(df[\"clean_description\"])\n",
    "    \n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(all_text)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Word Cloud of Job Descriptions\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9c157",
   "metadata": {},
   "source": [
    "## 5. Skill Extraction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skill-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    extractor = SkillExtractor()\n",
    "    skill_counts = Counter()\n",
    "    \n",
    "    for text in df[\"job_description\"].dropna():\n",
    "        for match in extractor.extract(text):\n",
    "            skill_counts[match.skill] += match.occurrences\n",
    "\n",
    "    skill_df = pd.DataFrame(\n",
    "        [\n",
    "            {\"skill\": skill, \"count\": count}\n",
    "            for skill, count in skill_counts.most_common(20)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if not skill_df.empty:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(data=skill_df, x='count', y='skill', palette='viridis')\n",
    "        plt.title('Top 20 Extracted Skills')\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Skill')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No skills extracted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
